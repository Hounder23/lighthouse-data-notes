{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data Using Pandas\n",
    "\n",
    "In this activity, we will demonstrate how you can clean the data in Python using appropriate Python functions and libraries. \n",
    "\n",
    "Python is a great language for doing data analysis, primarily because of the fantastic ecosystem of data-centric python packages. Pandas is one of those packages and makes importing and analyzing data much easier.\n",
    "An important part of Data analysis is analyzing Duplicate Values and removing them. Pandas drop_duplicates() method helps in removing duplicates from the data frame.\n",
    "\n",
    "\n",
    "## Data Cleaning: Null values\n",
    "\n",
    "- Sometimes values will be blank in your data\n",
    "- It could be an error; it could be the data was not available\n",
    "- There are some techniques to deal with it; all of them are imperfect\n",
    "- These techniques should be employed only if you can't get better data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reading a CSV file\n",
    "\n",
    "- Dataset: https://www.kaggle.com/uciml/pima-indians-diabetes-database/data#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "diabetes_df = pd.read_csv('diabetes.csv')\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Null values: Summary of the data\n",
    "\n",
    "- Sometimes null values aren't exactly NaNs\n",
    "- They are encoded as -1 or 9999 etc.\n",
    "- Sometimes it's 0. \n",
    "- Does 0 make sense for some of these categories??\n",
    "\n",
    "A good function to use to quickly find out how data in each column is distributed is `pd.describe()`. This function provides descriptive statistics, including those that summarize the central tendency, dispersion and shape of a dataset’s distribution. When providing these descriptive statistics, it does so by excluding NaN values.\n",
    "\n",
    "The `pd.describe()` function can analyzes both numeric and object series, as well as DataFrame column sets of mixed data types. There is an optional parametr `include`. When `incldue=\"all\"`, the output also include columns that are not nuemrical.\n",
    "\n",
    "When null values aren't showing up aas NaNs but rather coded as some other numebr, using `pd.describe()` can help us locate that. For example, the following code block tells us that the minimum value for the Glucose column is 0. That doesn't make sense. Similarly, Blood Pressure, Skin Thickness, Insulin level, and BMI columns all have minimum values of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out where the NaNs are (this only works if the data is actually NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Null values: Encoding true NaNs as NaNs\n",
    "\n",
    "The null value shouldn't be used in summary calculations (e.g., average, count), so it is important to identify if missing values are somehow coded as some extreme numerical value.\n",
    "\n",
    "Some columns have a lot of what we think could be missing values, and it is important to identify what those columns are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "763    False\n",
       "764    False\n",
       "765    False\n",
       "766    False\n",
       "767    False\n",
       "Name: Glucose, Length: 768, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['Glucose']==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass in a list of column names (`cols_missing_vals`), and use it to find out how many missing values there are in each of these columns.\n",
    "\n",
    "To Select multiple columns, put a column names inside a Python list, and put that list inside a pair of square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glucose            5\n",
       "BloodPressure     35\n",
       "SkinThickness    227\n",
       "Insulin          374\n",
       "BMI               11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_missing_vals = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI'] # cols with missing values\n",
    "(diabetes_df[cols_missing_vals] == 0).sum() # count number of 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can fill the 0s in these columns as `np.NaN`. This will code the missing value to be NaN. \n",
    "\n",
    "Because these values are now NaN, when we compute summary statistics, they won't be factored into the calculation, since they are no longer a number. If this step was not done, the 0s would impact the summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   0\n",
       "Glucose                       5\n",
       "BloodPressure                35\n",
       "SkinThickness               227\n",
       "Insulin                     374\n",
       "BMI                          11\n",
       "DiabetesPedigreeFunction      0\n",
       "Age                           0\n",
       "Outcome                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df[cols_missing_vals] = diabetes_df[cols_missing_vals].replace(0, np.NaN) # replace 0's with NaNs\n",
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Null values: Removing rows with missing values\n",
    "- Could be a good idea if there aren't too many records removed\n",
    "- Let's do this for Glucose and BMI columns\n",
    "- documentation for pandas dropna() function: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n",
    "- `pd.dropna()` has a default parameter, how='any'. Possible input values are 'any', or 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping NAs (768, 9)\n",
      "Shape after dropping NAs for Glucose and BMI columns (752, 9)\n"
     ]
    }
   ],
   "source": [
    "# pd.dropna() has a default parameter, how='any'. Possible input values are 'any', or 'all'\n",
    "\n",
    "print(\"Shape before dropping NAs\", diabetes_df.shape)\n",
    "\n",
    "diabetes_df = diabetes_df.dropna(subset=['Glucose', 'BMI']) # drop rows with Glucose and BMI as NaN\n",
    "\n",
    "print(\"Shape after dropping NAs for Glucose and BMI columns\", diabetes_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Null values: using the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eddie\\AppData\\Local\\Temp\\ipykernel_17716\\289822400.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diabetes_df['SkinThickness'] = diabetes_df['SkinThickness'].fillna(value=diabetes_df['SkinThickness'].mean())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pregnancies                   0\n",
       "Glucose                       0\n",
       "BloodPressure                28\n",
       "SkinThickness                 0\n",
       "Insulin                     360\n",
       "BMI                           0\n",
       "DiabetesPedigreeFunction      0\n",
       "Age                           0\n",
       "Outcome                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in missing values with the average\n",
    "diabetes_df['SkinThickness'] = diabetes_df['SkinThickness'].fillna(value=diabetes_df['SkinThickness'].mean())\n",
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning: Duplicate Rows\n",
    "\n",
    "Pandas provides a good function to clean data from duplicate values: `pd.drop_duplicates()`. \n",
    "\n",
    "The `pd.drop_duplicates()` function has a few paramters that you can specify values:\n",
    "\n",
    "`subset`: Subset takes a column or list of column label. It’s default value is none. After passing columns, it will consider them only for duplicates. \n",
    "`keep`: keep is to control how to consider duplicate value. It has only three distinct value and default is ‘first’. \n",
    "\n",
    "- If ‘first’, it considers first value as unique and rest of the same values as duplicate.\n",
    "- If ‘last’, it considers last value as unique and rest of the same values as duplicate.\n",
    "- If False, it consider all of the same values as duplicates\n",
    "\n",
    "`inplace`: Boolean values, removes rows with duplicates if True.\n",
    "\n",
    "It then returns a DataFrame with removed duplicate rows depending on Arguments passed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing rows with the same value in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emp ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>E Mail</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Date of Joining</th>\n",
       "      <th>Salary</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Phone No.</th>\n",
       "      <th>County</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>859085</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>Laplante</td>\n",
       "      <td>M</td>\n",
       "      <td>aaron.laplante@hotmail.com</td>\n",
       "      <td>3/31/1978</td>\n",
       "      <td>6/24/2016</td>\n",
       "      <td>97879</td>\n",
       "      <td>536-71-5525</td>\n",
       "      <td>218-588-2428</td>\n",
       "      <td>Fillmore</td>\n",
       "      <td>Spring Valley</td>\n",
       "      <td>MN</td>\n",
       "      <td>55975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>775215</td>\n",
       "      <td>Abel</td>\n",
       "      <td>Varner</td>\n",
       "      <td>M</td>\n",
       "      <td>abel.varner@yahoo.com</td>\n",
       "      <td>5/1/1974</td>\n",
       "      <td>12/4/1997</td>\n",
       "      <td>187021</td>\n",
       "      <td>715-18-4802</td>\n",
       "      <td>701-817-8263</td>\n",
       "      <td>Bottineau</td>\n",
       "      <td>Antler</td>\n",
       "      <td>ND</td>\n",
       "      <td>58711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>967670</td>\n",
       "      <td>Adah</td>\n",
       "      <td>Hofmann</td>\n",
       "      <td>F</td>\n",
       "      <td>adah.hofmann@hotmail.com</td>\n",
       "      <td>3/15/1977</td>\n",
       "      <td>8/16/2001</td>\n",
       "      <td>101648</td>\n",
       "      <td>597-92-2979</td>\n",
       "      <td>262-906-6238</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Green Bay</td>\n",
       "      <td>WI</td>\n",
       "      <td>54313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>445332</td>\n",
       "      <td>Adaline</td>\n",
       "      <td>Byrnes</td>\n",
       "      <td>F</td>\n",
       "      <td>adaline.byrnes@charter.net</td>\n",
       "      <td>1/5/1990</td>\n",
       "      <td>2/22/2011</td>\n",
       "      <td>143179</td>\n",
       "      <td>731-28-0283</td>\n",
       "      <td>231-910-0633</td>\n",
       "      <td>Genesee</td>\n",
       "      <td>Burton</td>\n",
       "      <td>MI</td>\n",
       "      <td>48529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>466526</td>\n",
       "      <td>Adan</td>\n",
       "      <td>Wesley</td>\n",
       "      <td>M</td>\n",
       "      <td>adan.wesley@gmail.com</td>\n",
       "      <td>6/3/1970</td>\n",
       "      <td>8/28/2001</td>\n",
       "      <td>104606</td>\n",
       "      <td>171-86-9901</td>\n",
       "      <td>217-799-8172</td>\n",
       "      <td>Randolph</td>\n",
       "      <td>Walsh</td>\n",
       "      <td>IL</td>\n",
       "      <td>62297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>384939</td>\n",
       "      <td>Zenaida</td>\n",
       "      <td>Cavazos</td>\n",
       "      <td>F</td>\n",
       "      <td>zenaida.cavazos@gmail.com</td>\n",
       "      <td>4/27/1965</td>\n",
       "      <td>4/8/2000</td>\n",
       "      <td>95950</td>\n",
       "      <td>417-67-5948</td>\n",
       "      <td>229-925-1431</td>\n",
       "      <td>Monroe</td>\n",
       "      <td>Bolingbroke</td>\n",
       "      <td>GA</td>\n",
       "      <td>31004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>578209</td>\n",
       "      <td>Zora</td>\n",
       "      <td>Maupin</td>\n",
       "      <td>F</td>\n",
       "      <td>zora.maupin@aol.com</td>\n",
       "      <td>12/25/1957</td>\n",
       "      <td>7/16/1988</td>\n",
       "      <td>188869</td>\n",
       "      <td>257-99-2566</td>\n",
       "      <td>505-935-9867</td>\n",
       "      <td>San Miguel</td>\n",
       "      <td>Ribera</td>\n",
       "      <td>NM</td>\n",
       "      <td>87560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>150828</td>\n",
       "      <td>Zoraida</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>F</td>\n",
       "      <td>zoraida.sanchez@charter.net</td>\n",
       "      <td>3/29/1968</td>\n",
       "      <td>12/9/2015</td>\n",
       "      <td>126843</td>\n",
       "      <td>346-08-5092</td>\n",
       "      <td>212-305-3599</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>Meridale</td>\n",
       "      <td>NY</td>\n",
       "      <td>13806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>772602</td>\n",
       "      <td>Zula</td>\n",
       "      <td>Romeo</td>\n",
       "      <td>F</td>\n",
       "      <td>zula.romeo@verizon.net</td>\n",
       "      <td>1/18/1966</td>\n",
       "      <td>7/17/2011</td>\n",
       "      <td>168294</td>\n",
       "      <td>065-02-2599</td>\n",
       "      <td>212-317-3624</td>\n",
       "      <td>Onondaga</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>NY</td>\n",
       "      <td>13251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>455253</td>\n",
       "      <td>Zulma</td>\n",
       "      <td>Barnett</td>\n",
       "      <td>F</td>\n",
       "      <td>zulma.barnett@hotmail.com</td>\n",
       "      <td>5/14/1958</td>\n",
       "      <td>1/11/1980</td>\n",
       "      <td>152538</td>\n",
       "      <td>371-37-3370</td>\n",
       "      <td>219-996-7943</td>\n",
       "      <td>Greene</td>\n",
       "      <td>Koleen</td>\n",
       "      <td>IN</td>\n",
       "      <td>47439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1554 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Emp ID First Name Last Name Gender                       E Mail  \\\n",
       "4905  859085      Aaron  Laplante      M   aaron.laplante@hotmail.com   \n",
       "2621  775215       Abel    Varner      M        abel.varner@yahoo.com   \n",
       "1588  967670       Adah   Hofmann      F     adah.hofmann@hotmail.com   \n",
       "763   445332    Adaline    Byrnes      F   adaline.byrnes@charter.net   \n",
       "3516  466526       Adan    Wesley      M        adan.wesley@gmail.com   \n",
       "...      ...        ...       ...    ...                          ...   \n",
       "373   384939    Zenaida   Cavazos      F    zenaida.cavazos@gmail.com   \n",
       "4784  578209       Zora    Maupin      F          zora.maupin@aol.com   \n",
       "4348  150828    Zoraida   Sanchez      F  zoraida.sanchez@charter.net   \n",
       "668   772602       Zula     Romeo      F       zula.romeo@verizon.net   \n",
       "4276  455253      Zulma   Barnett      F    zulma.barnett@hotmail.com   \n",
       "\n",
       "     Date of Birth Date of Joining  Salary          SSN    Phone No.   \\\n",
       "4905     3/31/1978       6/24/2016   97879  536-71-5525  218-588-2428   \n",
       "2621      5/1/1974       12/4/1997  187021  715-18-4802  701-817-8263   \n",
       "1588     3/15/1977       8/16/2001  101648  597-92-2979  262-906-6238   \n",
       "763       1/5/1990       2/22/2011  143179  731-28-0283  231-910-0633   \n",
       "3516      6/3/1970       8/28/2001  104606  171-86-9901  217-799-8172   \n",
       "...            ...             ...     ...          ...           ...   \n",
       "373      4/27/1965        4/8/2000   95950  417-67-5948  229-925-1431   \n",
       "4784    12/25/1957       7/16/1988  188869  257-99-2566  505-935-9867   \n",
       "4348     3/29/1968       12/9/2015  126843  346-08-5092  212-305-3599   \n",
       "668      1/18/1966       7/17/2011  168294  065-02-2599  212-317-3624   \n",
       "4276     5/14/1958       1/11/1980  152538  371-37-3370  219-996-7943   \n",
       "\n",
       "          County           City State    Zip  \n",
       "4905    Fillmore  Spring Valley    MN  55975  \n",
       "2621   Bottineau         Antler    ND  58711  \n",
       "1588       Brown      Green Bay    WI  54313  \n",
       "763      Genesee         Burton    MI  48529  \n",
       "3516    Randolph          Walsh    IL  62297  \n",
       "...          ...            ...   ...    ...  \n",
       "373       Monroe    Bolingbroke    GA  31004  \n",
       "4784  San Miguel         Ribera    NM  87560  \n",
       "4348    Delaware       Meridale    NY  13806  \n",
       "668     Onondaga       Syracuse    NY  13251  \n",
       "4276      Greene         Koleen    IN  47439  \n",
       "\n",
       "[1554 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "# making data frame from csv file\n",
    "data = pd.read_csv(\"employees.csv\")\n",
    " \n",
    "# sorting by first name\n",
    "data.sort_values(\"First Name\", inplace = True)\n",
    " \n",
    "# dropping ALL duplicate values\n",
    "data.drop_duplicates(subset =\"First Name\",\n",
    "                     keep = False, inplace = True)\n",
    " \n",
    "# displaying data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing rows with all duplicate values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"employees.csv\")\n",
    "length1 = len(data)\n",
    " \n",
    "# manually inserting duplicate of a row of row 440\n",
    "data.loc[1001] = [data[\"Emp ID\"][440],\n",
    "                  data[\"First Name\"][440],\n",
    "                  data[\"Last Name\"][440],\n",
    "                  data[\"Gender\"][440],\n",
    "                  data[\"E Mail\"][440],\n",
    "                  data[\"Date of Birth\"][440],\n",
    "                  data[\"Date of Joining\"][440],\n",
    "                  data[\"Salary\"][440],\n",
    "                  data[\"SSN\"][440],\n",
    "                  data[\"Phone No. \"][440],\n",
    "                  data[\"County\"][440],\n",
    "                  data[\"City\"][440],\n",
    "                  data[\"State\"][440],\n",
    "                  data[\"Zip\"][440]]\n",
    "                   \n",
    "\n",
    "# length after adding row\n",
    "length2=  len(data)\n",
    " \n",
    "# sorting by first name\n",
    "data.sort_values(\"First Name\", inplace=True)\n",
    " \n",
    "# dropping duplicate values\n",
    "data.drop_duplicates(keep=False,inplace=True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning: Wrong Format\n",
    "\n",
    "The detailed walkthrough is covered in the Formatting Data activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6e0f8a12803683744c861614f716ee6d7b4737375095190f9e58ed1bf7efce1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
